{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Denna modul är för att testa olika modeller och parametrar \n","# för att hitta den bästa modellen för att förutsäga kryptovalutor\n","# Dessutom testar jag att ta med inflation och guldpriser som features\n","\n","# Nu används yfinance för att hämta data från Yahoo Finance\n","\n","# skall flyttas över till my_crypto.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sklearn\n","import xgboost as xgb\n","import catboost\n","from catboost import CatBoostClassifier\n","from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n","from xgboost import XGBClassifier\n","# from pytrends.request import TrendReq\n","# import pytrends\n","import sys\n","import numpy as np\n","import pandas as pd\n","import pickle\n","from datetime import datetime as dt\n","import yfinance as yf\n","import re\n","import preprocess as pp\n","import matplotlib.pyplot as plt \n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score    \n","from sklearn.pipeline import make_pipeline\n","from sklearn.impute import SimpleImputer\n","# plt.style.use('fivethirtyeight')\n","import plotly.express as px\n","import streamlit as st\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","from sklearn.model_selection import GridSearchCV\n","\n","#Import other useful libraries\n","import time\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from IPython.display import display\n","# set display witdh to 200\n","pd.set_option('display.width', 200)\n","# set display height to 500\n","pd.set_option('display.max_rows', 500)\n","pd.options.display.max_columns = 200    # default 20\n","pd.options.display.max_colwidth = 60  # default 50\n","# pd.options.display.precision = 4      # default 6\n","import logging\n","\n","# Starta upp logging och inkluder rad nummer\n","logging.basicConfig(level=logging.INFO, filemode='w', filename='krypto.log', force=True,\n","                    encoding='utf-8', format= '%(asctime)s - %(levelname)s - %(lineno)d - %(message)s')\n","logging.info('Startar')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Versioner av softvara som används i denna notebook:')\n","# print numpy version\n","print(f'numpy=={np.__version__}')\n","# print pandas version\n","print(f'pandas=={pd.__version__}')\n","# print matplotlib version\n","print('matplotlib=={}'.format(plt.matplotlib.__version__)) # type: ignore\n","# print yfinance version\n","print('yfinance=={}'.format(yf.__version__))\n","# print pytreands version\n","print('pytrends==4.8.0  by hand')\n","# print python-dateutil version\n","print('python-dateutil==2.8.2  by hand')\n","# print ta version\n","print('ta==0.10.2  by hand')\n","# print streamlit version\n","print('streamlit=={}'.format(st.__version__))\n","print('xgboost=={}'.format(xgb.__version__))\n","print('catboost=={}'.format(catboost.__version__))\n","print('sklearn=={}'.format(sklearn.__version__))\n","# print pandas-ta version\n","print('pandas-ta==0.3.14b0  by hand')\n","# print plotly version\n","print('plotly==5.3.1  by hand')\n","# print pickle version\n","print('pickle-versionen är samma som python-versionen')\n","# print python versionen\n","print('python=={}'.format(sys.version))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["För att hämta från yFinance väljer jag att använda följande tickers för learning och testing:  \n","**Mina egna:**  \n","['BTC-USD', 'ETH-USD','XRP-USD','BCH-USD','ZRX-USD']  \n","\n","**Samt 5 till:**  \n","Binance Coin (BNB-USD)  \n","Cardano (ADA-USD)  \n","Dogecoin (DOGE-USD)  \n","Polkadot (DOT-USD)  \n","Avalanche (AVAX-USD)  \n","\n","**Ytterligare 5 som får vara reserv:**  \n","Solana (SOL-USD)  \n","Chainlink (LINK-USD)  \n","Litecoin (LTC-USD)  \n","Chainlink (LINK-USD)  \n","Polygon (MATIC-USD)  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dessa 10 kryptovalutor valde jag som input till min ML\n","tickers = ['BTC-USD','ETH-USD','BCH-USD','XRP-USD','ZRX-USD','BNB-USD','ADA-USD','DOGE-USD','DOT-USD', 'AVAX-USD']\n","horizons=[2, 5, 60, 250]"]},{"cell_type":"markdown","metadata":{},"source":["## Get inflation data US and SE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def initiate_data(inflation, df_dates, lang_dict, value_name):\n","    # display(inflation)\n","    inflation = inflation.melt(\n","        id_vars=['Year'], var_name='month', value_name=value_name)\n","\n","    # use lang_dict to translate month names to numbers\n","    inflation['month'] = inflation['month'].map(lang_dict)\n","\n","    inflation['Date'] = pd.to_datetime(inflation['Year'].astype(\n","        str) + '-' + inflation['month'].astype(str))\n","    inflation.set_index('Date', inplace=True)\n","    inflation.drop(['Year', 'month'], axis=1, inplace=True)\n","    inflation = df_dates.merge(\n","        inflation, how='left', left_on='Date', right_index=True)\n","    inflation.set_index('Date', inplace=True)\n","    inflation[value_name] = inflation[value_name].astype(str)\n","    inflation[value_name] = inflation[value_name].str.replace(',', '.')\n","    inflation[value_name] = inflation[value_name].str.replace(\n","        chr(8209), chr(45))\n","    inflation[value_name] = inflation[value_name].astype(float)\n","    inflation[value_name].interpolate(method='linear', inplace=True)\n","    return inflation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","@st.cache_data\n","def get_inflation_data(graph=False):\n","    # Explain this function here        \n","    # Create a dataframe with dates from 1988-12-01 to today\n","    df_dates = pd.DataFrame(pd.date_range('1988-12-01', pd.to_datetime('today').date()), columns=['Date'])\n","    \n","    US_inflation = pd.read_html('https://www.usinflationcalculator.com/inflation/current-inflation-rates/')\n","    US_inflation = US_inflation[0]\n","    # replace the cell including string starting with \"Avail\" with the NaN\n","    US_inflation.replace(to_replace=r'^Avail.*$', value=np.nan, regex=True, inplace=True)\n","    # set the first row as the header and drop the first row\n","    US_inflation.columns = US_inflation.iloc[0]\n","    US_inflation.drop(US_inflation.index[0], inplace=True)\n","    US_inflation.drop('Ave', axis=1, inplace=True)\n","\n","    # SE_inflation = pd.DataFrame()\n","    SE_inflation = pd.read_html('https://www.scb.se/hitta-statistik/statistik-efter-amne/priser-och-konsumtion/konsumentprisindex/konsumentprisindex-kpi/pong/tabell-och-diagram/konsumentprisindex-med-fast-ranta-kpif-och-kpif-xe/kpif-12-manadersforandring/')\n","    SE_inflation = SE_inflation[0]\n","    SE_inflation.rename(columns={'År': 'Year'}, inplace=True)\n","\n","    se_dict = dict(Jan='1', Feb='2', Mar='3', Apr='4', Maj='5', Jun='6', Jul='7', Aug='8', Sep='9', Okt='10', Nov='11', Dec='12')\n","    us_dict = dict(Jan='1', Feb='2', Mar='3', Apr='4', May='5', Jun='6', Jul='7', Aug='8', Sep='9', Oct='10', Nov='11', Dec='12')\n","    \n","    SE_inflation = initiate_data(SE_inflation, df_dates, se_dict, value_name='SE_inflation')\n","    SE_inflation['SE_inflation'] = SE_inflation['SE_inflation'] / 10  # SE_inflation is in percent, divide by 10 to get decimal\n","    US_inflation = initiate_data(US_inflation, df_dates, us_dict,  value_name='US_inflation')\n","\n","    if graph:\n","        # Do a simple plot\n","        fig, ax = plt.subplots(figsize=(12, 10))\n","        # set the color of the liens to blue and green\n","        ax.plot(US_inflation.index, US_inflation['US_inflation'], color='green', label='USA')\n","        ax.plot(SE_inflation.index, SE_inflation['SE_inflation'], color='blue', label='Sverige')\n","        \n","        ax.set_xlabel('Date')\n","        ax.set_ylabel('Inflation')\n","        ax.legend()\n","        plt.show()\n","\n","    # concat and set one column to US_index and the other to SE_index\n","    inflations = pd.concat([US_inflation, SE_inflation], axis=1).copy()\n","    inflations = inflations.dropna()\n","    # Keep only US_inflation\n","    inflations = inflations[['US_inflation']]\n","    return inflations\n","\n","df_infl = get_inflation_data(graph=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(list(df_infl.columns))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fill up a dataframe with all days from 2005 up to today and set it as index\n","def get_all_dates():\n","    start_date = dt(2005, 1, 1)\n","    end_date = dt.today()\n","    dates = pd.date_range(start_date, end_date)\n","    df = pd.DataFrame(index=dates)\n","    return df\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get Gold data from yfinance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_gold_data():\n","    df_dates = pd.DataFrame(pd.date_range(\n","        '1988-12-01', pd.to_datetime('today').date()), columns=['Date'])\n","    df_dates.set_index('Date', inplace=True)\n","    # Hämta historiska guldprisdata (GLD är ticker-symbolen för SPDR Gold Shares ETF)\n","    gld_data = yf.download('GLD', end=dt.today().date(), progress=False)\n","    # gld_data.set_index('Date', inplace=True)\n","    \n","    # Behåll endast 'Close' priser och döp om kolumnen till 'GLD-USD'\n","    gld_data = gld_data[['Close']].rename(columns={'Close': 'GLD-USD'})\n","\n","    df_dates = pd.DataFrame(pd.date_range(start=gld_data.index[0], end=pd.to_datetime('today').date(), freq='D'), columns=['Date']) # type: ignore\n","\n","    df_dates.set_index('Date', inplace=True)\n","    gld_data = df_dates.merge(gld_data, how='left', left_on='Date', right_index=True)\n","    # interpolating missing values\n","    gld_data.interpolate(method='linear',inplace=True)\n","    return gld_data\n","\n","df_gold = get_gold_data()\n","\n","display(df_gold.shape)\n","df_gold.plot(figsize=(8, 6), title='Gold Price')\n","plt.gca().lines[0].set_color(\"goldenrod\")\n","plt.xlabel('Year')\n","\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Ladda ner all data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","def get_all(tickers):\n","    # starta timer\n","    start = time.time()\n","    # Funktionen används inte just nu    \n","    df_curr = pd.DataFrame()\n","    df_vol = pd.DataFrame()\n","    for ticker in tickers:\n","        # all_tickers = yf.download(ticker)\n","        yf_data = yf.download(ticker, period='24mo')\n","        yf_data = yf_data[['Close', 'Volume']]\n","        yf_data.columns = [ticker, 'Volume']                   \n","        df_curr[ticker] = yf_data[ticker]\n","        df_vol[ticker] = yf_data['Volume']\n","    df_curr.index = pd.to_datetime(df_curr.index)\n","    df_vol.index = pd.to_datetime(df_vol.index)\n","    # skriv ut hur lång tid det tog i sekunder avrundat till 1 decimal\n","    print(f'Tid för yfinance: {round(time.time() - start, 1)} sekunder')\n","    return df_curr, df_vol\n","\n","df_curr, df_vol = get_all(tickers)\n","\n","# interpolate missing values  \n","df_curr.interpolate(method='linear',inplace=True)\n","df_vol.interpolate(method='linear',inplace=True)\n","print('med yfinance')\n","display(df_curr.head(3))\n","display(df_vol.head(3))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# FOr backtesting\n","def fit_predict(train, test, target, predictors, model, proba_val=None):\n","    \n","    if train[target].nunique() < 2:\n","        print('kolumner i train',train.columns)\n","        print('kolumner i test',test.columns)\n","        print('target',target)\n","        print('predictors',predictors)\n","        print('train\\n',train[target].value_counts())\n","        print('test\\n',test[target].value_counts())\n","        print(\n","            f\"Skipping training for target {target} as it has only one unique value in the training data.\")\n","        # stäng ner programmet\n","        sys.exit()\n","        \n","    model.fit(train[predictors], train[target])\n","\n","    if proba_val:  # använd proba\n","        preds = model.predict_proba(test[predictors])[:, 1]\n","        preds[preds >= proba_val] = 1\n","        preds[preds < proba_val] = 0\n","    else:    # använd predict utan proba\n","        preds = model.predict(test[predictors])\n","\n","    preds = pd.Series(preds, index=test.index, name=\"Predictions\")\n","    combined = pd.concat([test[target], preds], axis=1)\n","\n","    return combined\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Beräkna nya kolumner (predictors)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_curr.tail(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### get the data ###\n","df_curr, df_vol = get_all(tickers)\n","print('curr:',df_curr.shape)\n","print('vol:',df_vol.shape)\n","# inflations = get_inflation_data(graph=False)\n","print('inflations:',df_infl.shape)\n","df_gold = get_gold_data()\n","print('gold:',df_gold.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Vi gör viss preprocessing för en valuta i taget - nya kolumner"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### preprocessing ###\n","df_dict = {}\n","df = pp.preprocessing_currency(df_curr)\n","if df is not None:\n","    print('Antal NaN', df.isna().any().sum())\n","\n","    print()\n","    df_dict = {}  # en dictionary med samtlig nya dataframes\n","    for cnt, column_name in enumerate(df.columns):\n","        df_name = f'df_{column_name}'\n","        df_dict[df_name] = pp.preprocess(df_curr[[column_name]],df_vol[[column_name]], df_gold, df_infl)\n","        print(cnt+1, column_name)\n","\n","display(df_dict.keys())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_dict['df_BTC-USD'].head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["the_dict = df_dict.copy()\n","# Slå ihop alla df_dict till  df2 med gemnsamma kolumner\n","for df_name in the_dict:\n","    the_dict[df_name] = the_dict[df_name].rename(\n","        columns={the_dict[df_name].columns[0]: 'Close'})\n","    # reset index in df_dict[df_name] but keep Date column\n","    the_dict[df_name] = the_dict[df_name].reset_index(drop=False)\n","    # add Ticker column to df_dict[df_name]\n","    the_dict[df_name]['Ticker'] = df_name\n","\n","df2 = pd.concat(the_dict.values(), axis=0)\n","df2.sort_values(by=['Date'], inplace=True)\n","df2.query('Date == \"2023-05-01\" and Ticker == \"df_DOGE-USD\"')\n","df2.set_index('Date', inplace=True)\n","display(df2.head(3))\n","display(df2.tail(3))\n","display(df2.columns)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# compute Tommorow's price to be Close next day\n","df2['Tomorrow'] = df2.groupby('Ticker')['Close'].shift(-1)\n","\n","# compute the percentage change\n","df2['Percentage Change'] = (df2['Tomorrow'] - df2['Close']) / df2['Close'] * 100\n","\n","df2['y1'] = (df2['Tomorrow'] > df2['Close']).astype(int)\n","df2.dropna(inplace=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Preprocessing för alla valutor tillsammans"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictors = ['Close','Ratio_2', 'Trend_2', 'Ratio_5', 'Trend_5', 'Ratio_30', 'Trend_30', 'Ratio_60', 'Trend_60', 'Ratio_90', 'Trend_90',\n","                  'Ratio_250', 'Trend_250', 'GLD-USD', 'GLD_Ratio_2', 'GLD_Ratio_5', 'GLD_Ratio_30', 'GLD_Ratio_60', 'GLD_Ratio_90', 'GLD_Ratio_250',\n","                  'Volume', 'vol_Ratio_2', 'vol_Ratio_5', 'vol_Ratio_30', 'vol_Ratio_60', 'vol_Ratio_90', 'vol_Ratio_250',\n","                  'US_inflation', 'infl_Ratio_75', 'infl_Ratio_90', 'infl_Ratio_250', 'diff', 'before_kvot','before_up']\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(df2.columns))\n","len(predictors)\n","# skillnaden mellan columns och predictors är 'y1', 'Tomorrow', 'Percentage Change'\n","predictors_diff = [col for col in df2.columns if col not in predictors]\n","predictors_diff"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","tscv = TimeSeriesSplit(n_splits=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(predictors+['y1'])\n","X = df2[predictors].dropna()\n","y = df2['y1']\n","print(X.shape)\n","print(y.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Välj mellan GridSearch och RandomSearch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["randomsearch = True   # RandmSearchCV för de två tunga modellerna\n","\n","\n","def combinations(param_list):\n","    total_combinations = 1\n","    for key in param_list:\n","        if key.startswith('classifier__'):\n","            total_combinations *= len(param_list[key])\n","    return total_combinations\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the hyperparameters for each dictionary\n","# each having a key as ‘classifier’ and value as estimator object.\n","#The hyperparameter keys should start with the word classifier separated\n","# by ‘__’ (double underscore)\n","\n","# Define parameters for CatBoostClassifier\n","paramCat = {}\n","paramCat['classifier__iterations'] = [75, 100, 250, 300, 325, 350]\n","paramCat['classifier__depth'] = [ 3, 4, 5, 7, 9]\n","# paramCat['classifier__class_weights'] = [{0: 1, 1: 1}, {0: 1, 1: 2} ]\n","paramCat['classifier__learning_rate'] = [0.01, 0.03, 0.05, 0.07, 0.09]\n","paramCat['classifier'] = [CatBoostClassifier(random_state=42, verbose=False)]\n","print('Total combinations for CatBoostClassifier = ', combinations(paramCat))\n","\n","# Define parameters for XGBClassifier\n","paramXGB = {}\n","paramXGB['classifier__n_estimators'] = [75, 100, 250,300, 350]\n","paramXGB['classifier__max_depth'] = [2, 3, 5, 10, 12]\n","paramXGB['classifier__learning_rate'] = [0.01, 0.03, 0.05, 0.07, 0.09]\n","# paramXGB['classifier__scale_pos_weight'] = [1, 5, 10]\n","paramXGB['classifier'] = [XGBClassifier(\n","    random_state=42, eval_metric='logloss')]\n","print('Total combinations for XGBClassifier = ', combinations(paramXGB))\n","\n","\n","# Define parameters for Random Forest\n","paramRF = {}\n","paramRF['classifier__n_estimators'] = [75, 100, 200, 350, 400, 500]\n","paramRF['classifier__min_samples_split'] = [2, 5, 10, 12]\n","paramRF['classifier__max_depth'] = [ 5, 10, 12, 14]\n","paramRF['classifier__min_samples_leaf'] = [1,2,4]\n","paramRF['classifier__max_features'] = ['auto', 'sqrt']\n","paramRF['classifier__bootstrap'] = [True, False]\n","paramRF['classifier'] = [RandomForestClassifier(random_state=42)]\n","print('Total combinations for RandomForestClassifier = ', combinations(paramRF))\n","\n","# Define parameters for support vector machine (SVC)\n","paramSVC = {}\n","paramSVC['classifier__kernel'] = ['linear', 'rbf']\n","paramSVC['classifier__C'] = [0.01, 1, 10, 100]\n","paramSVC['classifier__gamma'] = ['scale', 'auto', 0.1, 1, 10]\n","paramSVC['classifier__shrinking'] = [True, False]\n","paramSVC['classifier'] = [SVC(random_state=42)]\n","print('Total combinations for SVC = ', combinations(paramSVC))\n","\n","# Define parameters for Logistic regression\n","paramLR = {}\n","paramLR['classifier__C'] = [0.01, 0.1, 1, 10, 20, 50]\n","paramLR['classifier__penalty'] = ['l1', 'l2']\n","paramLR['classifier__solver'] = ['liblinear', 'saga']  # or 'saga'\n","paramLR['classifier__class_weight'] = [None]\n","paramLR['classifier'] = [LogisticRegression(random_state=42)]\n","print('Total combinations for LogisticRegression = ', combinations(paramLR))\n","\n","# Define parameters for K neighbors classifier\n","paramKN = {}\n","paramKN['classifier__n_neighbors'] = [ 7, 10, 20, 30, 50,60]\n","paramKN['classifier__weights'] = ['uniform', 'distance']\n","paramKN['classifier__algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n","paramKN['classifier__leaf_size'] = [10, 30, 50, 70, 90]\n","paramKN['classifier'] = [KNeighborsClassifier()]\n","print('Total combinations for KNeighborsClassifier = ', combinations(paramKN))\n","\n","# Define parameters for Gradient boosting\n","paramGBC = {}\n","paramGBC['classifier__max_depth'] = [3, 5, 10, 20]\n","paramGBC['classifier__min_samples_leaf'] = [1, 2, 4]\n","paramGBC['classifier__min_samples_split'] = [ 5, 10, 12]\n","paramGBC['classifier__n_estimators'] = [10, 50, 100, 200, 300]\n","\n","# paramGBC['classifier__max_features'] = ['auto', 'sqrt', 'log2', None]\n","# paramGBC['classifier__subsample'] = [0.5, 0.8, 1.0]\n","# paramGBC['classifier__loss'] = ['deviance', 'exponential']\n","\n","paramGBC['classifier'] = [GradientBoostingClassifier(random_state=42)]\n","print('Total combinations for GradientBoostingClassifier = ', combinations(paramGBC))\n","\n","# define the pipeline to include scaling and the model.\n","# Prepare the pipeline for the 1st model, others will be loaded appropriately\n","#during the Grid Search\n","#This pipeline will be the input to cross_val_score, instead of the model.\n","steps = list()\n","steps.append(('scaler', StandardScaler()))\n","steps.append(('classifier', RandomForestClassifier(random_state=42)))\n","pipeline = Pipeline(steps=steps)\n","\n","#Capture all parameter dictionaries as a list\n","params = [paramSVC, paramLR, paramKN, paramGBC]\n","# Total parameters for all 5 models = 27+20+48+5+9 = 109"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### GridSearchCV för lätta modeller"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# take the time\n","start_time = time.time()\n","#Grid search - including cross validation\n","grid = GridSearchCV(pipeline, params, cv=tscv, n_jobs=-\n","                    1, scoring='roc_auc').fit(X, y)\n","\n","#Gridsearch object (in our case 'grid') stores all the information about\n","#the best model and corresponding hyperparameters.\n","# print the best parameters...\n","print(grid.best_params_)\n","\n","# print best score for the best model (in our case roc_auc score)\n","print(grid.best_score_)\n","\n","# Stats for each test - we have a total 125 tests\n","means = grid.cv_results_['mean_test_score']\n","params_summary = grid.cv_results_['params']\n","# print the time taken\n","print(\"--- %s seconds ---\" % round((time.time() - start_time),1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","#Capture all data into a Data Frame\n","df_res1 = pd.DataFrame(list(zip(means, params_summary)),\n","                  columns=['Mean Score', 'Parms']).sort_values(by=['Mean Score'], ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_res1 = df_res1.sort_values(by='Mean Score', ascending=False)\n","df_res1.to_csv('GridSearchResults1.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_res1 = pd.read_csv('GridSearchResults1.csv')\n","\n","df_res1.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### RandomizedSearchCV av de tre tunga modellerna"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if randomsearch:\n","    from sklearn.model_selection import RandomizedSearchCV\n","\n","    # Add the new parameter dictionaries to the list\n","    params = [paramCat, paramXGB, paramRF]\n","\n","    # Number of iterations for randomized search\n","    n_iter_search = 50\n","\n","    #### Random search RF - including cross validation ####\n","    # Take the time\n","    start_time = time.time()\n","    randomRF = RandomizedSearchCV(\n","        pipeline, param_distributions=params[2], n_iter=n_iter_search, cv=tscv, n_jobs=-1, scoring='roc_auc', random_state=42).fit(X, y)\n","\n","    # print the best parameters...\n","    print(randomRF.best_params_)\n","\n","    # print best score for the best model (in our case roc_auc score)\n","    print(randomRF.best_score_)\n","\n","    # Stats for each test - we have a total 48 tests\n","    meansRF = randomRF.cv_results_['mean_test_score']\n","    params_summaryRF = randomRF.cv_results_['params']\n","\n","    #Capture all data into a Data Frame\n","    df_resRF = pd.DataFrame(list(zip(meansRF, params_summaryRF)),\n","                            columns=['Mean Score', 'Parms'])\n","\n","    # Take the time\n","    print(\"--- The RF time was %s seconds ---\" %round((time.time() - start_time), 1))\n","    df_resRF = df_resRF.sort_values(by='Mean Score', ascending=False)\n","    df_resRF.to_csv('RandomSearchResultsRF.csv', index=False)\n","\n","    display(df_resRF.head())\n","    \n","    \n","    #### Random search XGB - including cross validation ####\n","    # Take the time\n","    start_time = time.time()\n","    randomXGB = RandomizedSearchCV(\n","        pipeline, param_distributions=params[1], n_iter=n_iter_search, cv=tscv, n_jobs=-1, scoring='roc_auc', random_state=42).fit(X, y)\n","\n","    # print the best parameters...\n","    print(randomXGB.best_params_)\n","\n","    # print best score for the best model (in our case roc_auc score)\n","    print(randomXGB.best_score_)\n","\n","    # Stats for each test - we have a total 48 tests\n","    meansXGB = randomXGB.cv_results_['mean_test_score']\n","    params_summaryXGB = randomXGB.cv_results_['params']\n","\n","    #Capture all data into a Data Frame\n","    df_resXGB = pd.DataFrame(list(zip(meansXGB, params_summaryXGB)),\n","                            columns=['Mean Score', 'Parms'])\n","\n","    # Take the time\n","    print(\"--- The XGB time was %s seconds ---\" % round((time.time() - start_time), 1))\n","    df_resXGB = df_resXGB.sort_values(by='Mean Score', ascending=False)\n","    df_resXGB.to_csv('RandomSearchResultsXGB.csv', index=False)\n","\n","    display(df_resXGB.head())\n","\n","    #### Random search CATB - including cross validation ####\n","    # Take the time\n","    start_time = time.time()\n","    randomCAT = RandomizedSearchCV(\n","        pipeline, param_distributions=params[0], n_iter=n_iter_search, cv=tscv, n_jobs=-1, scoring='roc_auc', random_state=42).fit(X, y)\n","\n","    # print the best parameters...\n","    print(randomCAT.best_params_)\n","\n","    # print best score for the best model (in our case roc_auc score)\n","    print(randomCAT.best_score_)\n","\n","    # Stats for each test - we have a total 144 tests\n","    mensCAT = randomCAT.cv_results_['mean_test_score']\n","    params_summaryCAT = randomCAT.cv_results_['params']\n","\n","    #Capture all data into a Data Frame\n","    df_resCAT = pd.DataFrame(list(zip(mensCAT, params_summaryCAT)),\n","                            columns=['Mean Score', 'Parms'])\n","    df_resCAT =df_resCAT.sort_values(by='Mean Score', ascending=False)  \n","    df_resCAT.to_csv('RandomSearchResultsCAT.csv', index=False)\n","\n","    display(df_resCAT.head())\n","    # Take the time\n","    print(\"--- The Cat time was %s seconds ---\" % round((time.time() - start_time), 1))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### GridSearchCV även för de tunga"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not randomsearch:\n","    # Make GridSearch one by one for each model - because it takes so long time\n","    params = [paramCat, paramXGB, paramRF]\n","\n","    #### search XGB ####\n","    start_time = time.time()\n","    grid2a = GridSearchCV(pipeline, params, cv=tscv, n_jobs=-\n","                        1, scoring='roc_auc').fit(X, y)\n","\n","    # print the best parameters...\n","    print(grid2a.best_params_)\n","\n","    # print best score for the best model (in our case roc_auc score)\n","    print(grid2a.best_score_)\n","\n","    # Stats for each test - we have a total 48 tests\n","    means2a = grid2a.cv_results_['mean_test_score']\n","    params_summary2a = grid2a.cv_results_['params']\n","\n","    #Capture all data into a Data Frame\n","    df_resRF = pd.DataFrame(list(zip(means2a, params_summary2a)),\n","                    columns=['Mean Score', 'Parms'])\n","\n","    df_resRF.to_csv('GridSearchResults2a.csv', index=False)\n","\n","    # Take the time\n","    print(\"--- The time was %s seconds ---\" % round((time.time() - start_time),1))\n","    \n","    df_resRF = pd.read_csv('GridSearchResults2a.csv').sort_values(\n","        by='Mean Score', ascending=False)\n","\n","    df_resRF.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not randomsearch:\n","    #### Grid search CATB ####\n","    # Take the time\n","    start_time = time.time()\n","    grid2b = GridSearchCV(pipeline, params[:1], cv=tscv, n_jobs=-\n","                        1, scoring='roc_auc').fit(X, y)\n","    # print the best parameters...\n","    print(grid2b.best_params_)\n","\n","    # print best score for the best model (in our case roc_auc score)\n","    print(grid2b.best_score_)\n","\n","    # Stats for each test - we have a total 144 tests\n","    meansXGB = grid2b.cv_results_['mean_test_score']\n","    params_summaryXGB = grid2b.cv_results_['params']\n","\n","    #Capture all data into a Data Frame\n","    df_resXGB = pd.DataFrame(list(zip(meansXGB, params_summaryXGB)), # type: ignore\n","                            columns=['Mean Score', 'Parms'])\n","\n","    df_resXGB.to_csv('GridSearchResults2b.csv', index=False)\n","\n","    # Take the time\n","    print(\"--- The time was %s seconds ---\" % round((time.time() - start_time),1))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Summera alla modellers performance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_res1 = pd.read_csv('GridSearchResults1.csv')\n","\n","if randomsearch:\n","    df_resRF = pd.read_csv('RandomSearchResultsRF.csv')\n","    df_resRF['Model'] = 'RandomForrestClassifier'\n","    df_resXGB = pd.read_csv('RandomSearchResultsXGB.csv')\n","    df_resXGB['Model'] = 'XGBoost_Classifier'\n","    df_resCAT = pd.read_csv('RandomSearchResultsCAT.csv')\n","    df_resCAT['Model'] = 'CatBoostClassifier'\n","else:\n","    df_resRF = pd.read_csv('GridSearchResults2a.csv')\n","    df_resRF['Model'] = 'WARNING change this'\n","    df_resXGB = pd.read_csv('GridSearchResults2b.csv')\n","    df_resXGB['Model'] = 'WARNING change this'\n","    df_resCAT = pd.DataFrame()\n","\n","df_res = pd.concat([df_res1, df_resRF, df_resXGB, df_resCAT], ignore_index=True).sort_values(\n","    by='Mean Score', ascending=False)\n","df_res.to_csv('GridSearchResults.csv', index=False)\n","\n","\n","def extract_model_and_params(row):\n","    model_regex = r'\\'classifier\\':\\s*([^,]+)'\n","    param_regex = r'\\'classifier__([a-zA-Z0-9_]+)\\':\\s*([^,}]+)'\n","\n","    model_match = re.search(model_regex, row['Parms'])\n","    model = model_match.group(1) if model_match else 'Unknown'\n","    # print(type(row.Model))\n","    model = 'CatBoostClassifier' if 'CatBoostClassifier' == row.Model else model\n","    model = 'XGBoost_Classifier' if 'XGBoost_Classifier' == row.Model else model\n","    model = 'RandomForrestClassifier' if 'RandomForrestClassifier' == row.Model else model\n","    # Ersätt objektreferenser med klassnamn\n","    model = re.sub(r'<[^>]*>', lambda x: 'CatBoostClassifier' if 'catboost' in x.group(0)\n","                   else x.group(0).split('.')[1], model)\n","    # print(model)\n","    # Ta bort allt efter och inklusive '('\n","    model = re.sub(r'\\(.*|\\}.*', '', model).strip()\n","\n","    params = re.findall(param_regex, row['Parms'])\n","    params_clean = {k: v.strip() for k, v in params}\n","    # print(params_clean)\n","    return pd.Series([model, params_clean])\n","\n","print(df_res.columns)\n","print(df_res.Model.unique())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Skapa nya kolumner för model och parametrar utan 'classifier__' prefix\n","\n","df_res[['Model', 'Parameters_clean']] = df_res.apply(extract_model_and_params, axis=1)\n","df_res.sort_values(by='Mean Score', ascending=False, inplace=True)\n","# Ta bort den gamla 'Parameters' kolumnen\n","df_res = df_res.drop(columns=['Parms'])\n","\n","print(\n","    f'The winner is {df_res.iloc[0].Model} with params\\n {df_res.iloc[0][\"Parameters_clean\"]}')\n","\n","print()\n","pd.set_option('display.max_colwidth', None)\n","print('De bästa resultaten per modell sorterade efter Mean Score')\n","m = df_res.groupby('Model').head(1).sort_values(by='Mean Score', ascending=False)\n","print(m[['Model', 'Mean Score', 'Parameters_clean']].to_string(index=False))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\"\"\"Det nyaste resultatet (24/5)   \n","CatBoostClassifier          0.561043 {'learning_rate': '0.01', 'iterations': '350', 'depth': '9'}  \n","RandomForrestClassifier     0.559331 {'n_estimators': '100', 'min_samples_split': '2', 'min_samples_leaf': '1', 'max_features': ''auto'', 'max_depth': '12', 'bootstrap': 'True'}  \n","GradientBoostingClassifier  0.555753 {'max_depth': '20', 'min_samples_leaf': '2', 'min_samples_split': '10', 'n_estimators': '100'}  \n","SVC                         0.552393 {'C': '1', 'gamma': ''scale'', 'kernel': ''rbf'', 'shrinking': 'False'}    \n","LogisticRegression          0.551225 {'C': '0.1', 'class_weight': 'None', 'penalty': ''l1'', 'solver': ''saga''}  \n","XGBoost_Classifier          0.550834 {'n_estimators': '300', 'max_depth': '12', 'learning_rate': '0.05'}  \n","KNeighborsClassifier        0.547992 {'algorithm': ''kd_tree'', 'leaf_size': '90', 'n_neighbors': '50', 'weights': ''uniform''}  \n","\n","    resultatet (23/5)   \n","RandomForrestClassifier     0.561302 {'n_estimators': ures': ''auto'', 'max_depth': '14', 'bootstrap': 'True'}  \n","CatBoostClassifier          0.556916 {'learning_rate': '0.01', 'iterations': '325', 'depth': '7'}  \n","GradientBoostingClassifier  0.553260 {'max_depth': '10', 'min_samples_leaf': '1', 'min_samples_split': '10', 'n_estimators': '50'}  \n","LogisticRegression          0.548242 {'C': '0.1', 'class_weight': 'None', 'penalty': ''l1'', 'solver': ''saga''}  \n","SVC                         0.546807 {'C': '1', 'gamma': ''scale'', 'kernel': ''rbf'', 'shrinking': 'True'}  \n","KNeighborsClassifier        0.544760 {'algorithm': ''auto'', 'leaf_size': '10', 'n_neighbors': '60', 'weights': ''uniform''}  \n","XGBoost_Classifier          0.539619 {'n_estimators': '100', 'max_depth': '3', 'learning_rate': '0.07'}  \n","\n","\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\" Det äldre resultatet                                                                                                                              Parameters_clean\n","XGBoost_Classifier      0.557098 {'n_estimators': '250', 'max_depth': '12', 'learning_rate': '0.09'}\n","GradientBoostingClassif 0.552184 {'max_depth': '10', 'min_samples_leaf': '4', 'min_samples_split': '12', 'n_estimators': '300'}\n","CatBoostClassifier      0.551837 {'learning_rate': '0.09', 'iterations': '300', 'depth': '2'}\n","RandomForrestClassifier 0.548157 {'n_estimators': '350', 'min_samples_split': '5', 'min_samples_leaf': '4', 'max_features': ''auto'', 'max_depth': '10', 'bootstrap': 'False'}\n","SVC                     0.540441 {'C': '1', 'gamma': ''scale'', 'kernel': ''rbf'', 'shrinking': 'True'}\n","LogisticRegression      0.528314 {'C': '50', 'class_weight': 'None', 'penalty': ''l2'', 'solver': ''liblinear''}\n","KNeighborsClassifier    0.517581 {'algorithm': ''ball_tree'', 'leaf_size': '10', 'n_neighbors': '50', 'weights': ''distance''}\n","\"\"\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Skapa en modell av den bästa ovan"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_model = 'CB'\n","# Modellen baseras på mina förvalda tickers\n","print(tickers)\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def XGB(X, y):\n","    import xgboost\n","    from xgboost import XGBClassifier\n","    # Skapa en StandardScaler\n","    scaler = StandardScaler()\n","\n","    # Förbered en pipeline som först skalar datan och sedan kör XGBoost\n","    XGB_dict = {'n_estimators': 250, 'max_depth': 12, 'learning_rate': 0.09}\n","    model = Pipeline([\n","        ('scaler', scaler),\n","        ('classifier', XGBClassifier(**XGB_dict))\n","    ])\n","\n","    # Träna modellen med datan X och målvariabeln y\n","    model.fit(X, y)\n","    print(f'xgboost version: {xgboost.__version__}')\n","    return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def RF(X, y):\n","    from sklearn.ensemble import RandomForestClassifier\n","    # Skapa en StandardScaler\n","    scaler = StandardScaler()\n","\n","    # Förbered en pipeline som först skalar datan och sedan kör RF\n","    rf_dict={'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 14, 'bootstrap': True}\n","    model = Pipeline([\n","        ('scaler', scaler),\n","        ('classifier', RandomForestClassifier(**rf_dict))\n","    ])\n","\n","    # Träna modellen med datan X och målvariabeln y\n","    model.fit(X, y)\n","\n","    # print randomforest version\n","    print(f'randomforest version: {sklearn.__version__}')\n","\n","    return model\n","\n","\n","def CB(X, y):\n","    from catboost import CatBoostClassifier\n","    # Skapa en StandardScaler\n","    scaler = StandardScaler()\n","\n","    # Förbered en pipeline som först skalar datan och sedan kör CatBoost\n","    cb_dict = {'learning_rate': 0.01, 'iterations': 350, 'depth': 9}\n","    model = Pipeline([\n","        ('scaler', scaler),\n","        ('classifier', CatBoostClassifier(**cb_dict))\n","    ])\n","    \n","    \n","    # Träna modellen med datan X och målvariabeln y\n","    model.fit(X, y)\n","\n","    # print catboost version\n","    print(f'catboost version: {catboost.__version__}')\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","if best_model == 'RF':\n","    my_model = RF(X, y)\n","elif best_model == 'XGB':    \n","    my_model = XGB(X, y)\n","elif best_model == 'CB':    \n","    my_model = CB(X, y)    \n","else:\n","    print('No model selected')\n","    sys.exit()\n","\n","print(f'sklearn version: {sklearn.__version__}')\n","# save my_model\n","pickle.dump(my_model, open(\"my_model.pkl\", \"wb\"))\n","\n","# load my_model\n","my_model = pickle.load(open(\"my_model.pkl\", \"rb\"))  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","np.sum((my_model.predict(X) == y))/len(y)\n","# my_model.get_params()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Tester"]}],"metadata":{"colab":{"name":"ETH pedict.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"metadata":{"interpreter":{"hash":"0f941ce24081e27d29fe825b4677fc955a82211890bd8dd12500b5500b9e4ea7"}},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"}}},"nbformat":4,"nbformat_minor":2}
